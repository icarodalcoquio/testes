#!/usr/bin/env python3
"""Reproduz a escolha de categorias de desgravação (cronograma) da oferta EFTA.

Sem dependências externas: lê .xlsx via XML interno e gera .csv.
"""

import argparse
import csv
import re
import zipfile
import xml.etree.ElementTree as ET
from collections import defaultdict

NS = {
    "a": "http://schemas.openxmlformats.org/spreadsheetml/2006/main",
    "r": "http://schemas.openxmlformats.org/officeDocument/2006/relationships",
}


def pad8(value):
    s = str(value).strip()
    s = re.sub(r"\.0$", "", s)
    digits = "".join(ch for ch in s if ch.isdigit())
    return digits.zfill(8) if digits else ""


def normalize(s):
    return str(s).strip().upper()


def parse_fp(stage):
    m = re.fullmatch(r"FP(\d+)%Y(\d+)", normalize(stage))
    if not m:
        return None
    return int(m.group(1)), int(m.group(2))


def choose_stage_conservative(stages):
    clean = [normalize(s) for s in stages if str(s).strip()]
    if not clean:
        return ""
    if len(set(clean)) == 1:
        return clean[0]
    if "E" in clean:
        return "E"
    if "TRQ" in clean:
        return "TRQ"

    fp_pairs = [p for p in (parse_fp(s) for s in clean) if p is not None]
    if fp_pairs:
        min_pct = min(p for p, _ in fp_pairs)
        max_year_for_min = max(y for p, y in fp_pairs if p == min_pct)
        return f"FP{min_pct}%Y{max_year_for_min}"

    numeric = [int(s) for s in clean if re.fullmatch(r"\d+", s)]
    if numeric:
        return str(max(numeric))

    if "FREE" in clean:
        return "FREE"

    return clean[0]


def stage_to_cronograma(stage):
    s = normalize(stage)
    if not s:
        return ""
    if s == "FREE":
        return "Duty free"
    if s == "E":
        return "Excluded"
    if s == "TRQ":
        return "TQR"
    if re.fullmatch(r"\d+", s):
        return s

    fp = parse_fp(s)
    if fp:
        pct, year = fp
        if year == 0:
            return f"Tariff preference of {pct}%"
        return f"Tariff preference of up to {pct}%"

    return s


def _col_idx(cell_ref):
    col = re.match(r"[A-Z]+", cell_ref).group(0)
    idx = 0
    for ch in col:
        idx = idx * 26 + ord(ch) - 64
    return idx - 1


def _load_shared_strings(zf):
    if "xl/sharedStrings.xml" not in zf.namelist():
        return []
    root = ET.fromstring(zf.read("xl/sharedStrings.xml"))
    strings = []
    for si in root.findall("a:si", NS):
        txt = "".join(t.text or "" for t in si.findall(".//a:t", NS))
        strings.append(txt)
    return strings


def _workbook_sheets(zf):
    wb = ET.fromstring(zf.read("xl/workbook.xml"))
    rels = ET.fromstring(zf.read("xl/_rels/workbook.xml.rels"))
    rel_map = {r.attrib["Id"]: r.attrib["Target"] for r in rels}
    out = []
    for sh in wb.findall("a:sheets/a:sheet", NS):
        rid = sh.attrib["{http://schemas.openxmlformats.org/officeDocument/2006/relationships}id"]
        target = rel_map[rid]
        if not target.startswith("xl/"):
            target = "xl/" + target
        out.append((sh.attrib["name"], target))
    return out


def read_xlsx_rows(path, sheet_name=None):
    with zipfile.ZipFile(path) as zf:
        sst = _load_shared_strings(zf)
        sheets = _workbook_sheets(zf)
        if sheet_name is None:
            _, target = sheets[0]
        else:
            target = next(t for n, t in sheets if n == sheet_name)

        root = ET.fromstring(zf.read(target))
        rows = []
        for row in root.findall(".//a:sheetData/a:row", NS):
            vals = {}
            for c in row.findall("a:c", NS):
                idx = _col_idx(c.attrib.get("r", "A1"))
                typ = c.attrib.get("t")
                v = c.find("a:v", NS)
                val = ""
                if typ == "s" and v is not None and v.text:
                    val = sst[int(v.text)]
                elif typ == "inlineStr":
                    is_node = c.find("a:is", NS)
                    if is_node is not None:
                        val = "".join(t.text or "" for t in is_node.findall(".//a:t", NS))
                elif v is not None and v.text is not None:
                    val = v.text
                vals[idx] = val

            max_c = max(vals.keys()) if vals else -1
            rows.append([vals.get(i, "") for i in range(max_c + 1)])
        return rows


def find_header(rows, must_have):
    for i, row in enumerate(rows):
        s = {str(c).strip() for c in row}
        if all(name in s for name in must_have):
            return i, row
    raise ValueError(f"Cabeçalho não encontrado para colunas: {must_have}")


def row_dicts(rows, header_idx):
    header = rows[header_idx]
    out = []
    for r in rows[header_idx + 1 :]:
        if not any(str(c).strip() for c in r):
            continue
        rr = r + [""] * (len(header) - len(r))
        out.append({header[i]: rr[i] for i in range(len(header))})
    return out


def main(orig_path, corr_path, trans_path, out_csv, target_example=None):
    orig_rows = read_xlsx_rows(orig_path)
    corr_rows = read_xlsx_rows(corr_path)
    trans_rows = read_xlsx_rows(trans_path)

    i_orig, _ = find_header(orig_rows, ["Tariff Line", "Staging category"])
    i_corr, _ = find_header(corr_rows, ["NCM_2012", "NCM_2017"])

    trans_header_markers = ["NCM ENERO DE 2021", "Descripción Acuerdo"]
    try:
        i_trans, _ = find_header(trans_rows, trans_header_markers)
        trans_mode = "acordo_exemplo"
    except ValueError:
        i_trans, _ = find_header(trans_rows, ["NCM", "Descrição"])
        trans_mode = "oferta_transposta"

    orig = row_dicts(orig_rows, i_orig)
    corr = row_dicts(corr_rows, i_corr)
    trans = row_dicts(trans_rows, i_trans)

    stage_by_old = {}
    for r in orig:
        code = pad8(r.get("Tariff Line", ""))
        if code:
            stage_by_old[code] = str(r.get("Staging category", "")).strip()

    parents_by_new = defaultdict(set)
    for r in corr:
        old_code = pad8(r.get("NCM_2012", ""))
        new_code = pad8(r.get("NCM_2017", ""))
        if old_code and new_code and old_code in stage_by_old:
            parents_by_new[new_code].add(old_code)

    output = []
    for r in trans:
        if trans_mode == "acordo_exemplo":
            new_code = pad8(r.get("NCM ENERO DE 2021", ""))
            desc = str(r.get("Descripción Acuerdo", "")).strip()
        else:
            new_code = pad8(r.get("NCM", ""))
            desc = str(r.get("Descrição", "")).strip()

        parents = sorted(parents_by_new.get(new_code, []))
        chosen_stage = choose_stage_conservative([stage_by_old[p] for p in parents]) if parents else ""
        cron = stage_to_cronograma(chosen_stage)

        output.append(
            {
                "ncm_destino": new_code,
                "descricao_destino": desc,
                "referencias_ncm_antigas": ",".join(parents),
                "qtd_pais": len(parents),
                "stage_escolhido": chosen_stage,
                "cronograma_escolhido": cron,
            }
        )

    with open(out_csv, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=list(output[0].keys()))
        w.writeheader()
        w.writerows(output)

    print(f"Arquivo gerado: {out_csv}")
    print(f"Linhas processadas: {len(output)}")

    if target_example:
        ex_rows = read_xlsx_rows(target_example)
        i_ex, _ = find_header(ex_rows, ["NCM ENERO DE 2021", "Cronograma"])
        ex = row_dicts(ex_rows, i_ex)
        expected = {}
        for r in ex:
            expected[pad8(r.get("NCM ENERO DE 2021", ""))] = str(r.get("Cronograma", "")).strip()

        hits = total = 0
        for row in output:
            code = row["ncm_destino"]
            if code and code in expected:
                total += 1
                if row["cronograma_escolhido"] == expected[code]:
                    hits += 1
        acc = (100 * hits / total) if total else 0.0
        print(f"Acurácia de cronograma vs exemplo: {hits}/{total} = {acc:.2f}%")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Reproduz a escolha de categorias de desgravação para a oferta EFTA transposta.")
    parser.add_argument("--orig", default="oferta efta origem (1).xlsx", help="Oferta EFTA de origem")
    parser.add_argument("--corr", default="TABELA CORRELAÇÃO OFICIAL.xlsx", help="Tabela oficial de correlação")
    parser.add_argument("--trans", default="ACORDO EFTA - EXEMPLO.xlsx", help="Arquivo transposto (destino)")
    parser.add_argument("--out", default="cronogramas_reproduzidos.csv", help="CSV de saída")
    parser.add_argument("--validar-com", default="ACORDO EFTA - EXEMPLO.xlsx", help="Arquivo com cronograma esperado para validar")
    args = parser.parse_args()

    main(args.orig, args.corr, args.trans, args.out, target_example=args.validar_com)
